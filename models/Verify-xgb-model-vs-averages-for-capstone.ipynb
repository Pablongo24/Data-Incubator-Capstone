{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if xgboost model is just an aggregate of averages from features\n",
    "This is to satisfy an inquiry from Dylan, in order to pass the Capstone project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import gc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "PARENTDIR = os.path.split(os.path.split(cwd)[0])[0]\n",
    "DATADIR = os.path.join(PARENTDIR, 'Capstone-WebApp-backup/models')\n",
    "CSV_file = (\"Dataset-for-ML-Model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(cwd, \"TDI-XGB_model.pkl\"), \"rb\") as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv(os.path.join(DATADIR, CSV_file), encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load label encoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(LabelEncoder)\n",
    "cols_transf = ['employer', 'job title', 'state', 'city']\n",
    "\n",
    "for col in cols_transf:\n",
    "    d[col] = LabelEncoder()\n",
    "    d[col].classes_ = np.load(os.path.join(cwd, '{}.npy'.format(col).replace(' ', '_')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this function requires a cleaned up 'location' column with no NaN or empty strings\n",
    "def get_city_state(df):\n",
    "    df[\"state\"] = df[\"location\"].str.split().str[-1]\n",
    "    df[\"location\"].apply(lambda x: \"\".join(x.split()[1:]))\n",
    "    df[\"location\"] = df[\"location\"].apply(lambda x: x.split(\" \"))\n",
    "    df[\"city\"] = df[\"location\"].str[:-1].apply(lambda x: \" \".join(x))\n",
    "    \n",
    "    df = df[['employer', 'job title', 'base salary', 'submit date',\n",
    "       'start date', 'case status', 'submit year', 'submit month', 'state', 'city']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = get_city_state(frame)\n",
    "X = frame[['employer', 'job title', 'submit year', 'state', 'city']]\n",
    "y = np.log1p(frame[['base salary']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_transform(df,cols_to_transf):\n",
    "    df_transf = df[cols_to_transf]\n",
    "    df_non_transf = df.drop(cols_to_transf, axis = 1)\n",
    "    \n",
    "    fit = df_transf.apply(lambda x: d[x.name].fit_transform(x))\n",
    "    \n",
    "    df = pd.concat([fit, df_non_transf], axis=1, join='outer')\n",
    "    return df\n",
    "\n",
    "\n",
    "def inverse_encoding(df,encoded_cols):\n",
    "    df_inverse = df[encoded_cols]\n",
    "    df_non_inv = df.drop(encoded_cols, axis = 1)\n",
    "    \n",
    "    df_inverse = df_inverse.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "    df = pd.concat([df_inverse, df_non_inv], axis=1, join='outer')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_future_data(df,cols_to_transf):\n",
    "    df_transf = df[cols_to_transf]\n",
    "    df_non_transf = df.drop(cols_to_transf, axis = 1)\n",
    "    \n",
    "    fit = df_transf.apply(lambda x: d[x.name].transform(x))\n",
    "    \n",
    "    df = pd.concat([fit, df_non_transf], axis=1, join='outer')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(LabelEncoder)\n",
    "cols_to_transf = ['employer','job title','state','city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fit_and_transform(X, cols_to_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.25 # assign proportion of dataset to test set split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "del X, y; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction RMSE = $20249.07\n",
      "R2 = 0.752\n"
     ]
    }
   ],
   "source": [
    "print('Prediction RMSE = ${:.2f}'.format(np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(predict)))))\n",
    "print('R2 = {:.3f}'.format(r2_score(y_test, predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dict = {\n",
    "    'employer':     ['Google Inc', 'Georgia Institute of Technology','Ove Arup & Partners PC'],\n",
    "    'job title':    ['Data Scientist', 'Assistant Professor', 'Mechanical Engineer'],\n",
    "    'state':        ['NY', 'GA', 'NY'],\n",
    "    'city':         ['New York', 'Atlanta', 'New York'],\n",
    "    'submit year':  [2018, 2018, 2018]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_new_data(predict_dict, cols_to_transf, future_data_column_order):\n",
    "    predict_df = pd.DataFrame.from_dict(predict_dict)\n",
    "    predict_df_transf = predict_df[cols_to_transf]\n",
    "    predict_df_non_transf = predict_df.drop(cols_to_transf, axis=1)\n",
    "    \n",
    "    for col in predict_df_transf.columns:\n",
    "        predict_df_transf[col] = predict_df_transf[col].str.upper()\n",
    "    \n",
    "    predict_df = pd.concat([predict_df_transf, predict_df_non_transf], axis=1, join='outer')   \n",
    "    predict_df = encode_future_data(predict_df,cols_to_transf)\n",
    "    predict_df = predict_df[future_data_column_order]\n",
    "    \n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data_column_order = ['employer', 'job title', 'state', 'city', 'submit year']\n",
    "predict_df = preprocess_new_data(predict_dict, cols_to_transf, future_data_column_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_new_data = xgb.DMatrix(predict_df)\n",
    "new_predictions = clf.predict(d_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your predicted salary as Data Scientist at Google Inc in New York is $150,212\n",
      "Your predicted salary as Assistant Professor at Georgia Institute of Technology in Atlanta is $107,958\n",
      "Your predicted salary as Mechanical Engineer at Ove Arup & Partners PC in New York is $81,461\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(predict_dict['job title']):\n",
    "    print('Your predicted salary as ' + title.title() + ' at ' + predict_dict['employer'][i] +\n",
    "          ' in ' + predict_dict['city'][i] + ' is ' + '${:,.0f}'.format(int(np.expm1(new_predictions[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check averages of entries above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_conditions = ['GOOGLE INC', 'GEORGIA INSTITUTE OF TECHNOLOGY','OVE ARUP & PARTNERS PC']\n",
    "city_conditions = ['NEW YORK', 'ATLANTA', 'NEW YORK']\n",
    "state_conditions = ['NY', 'GA', 'NY']\n",
    "title_conditions = ['DATA SCIENTIST', 'ASSISTANT PROFESSOR', 'MECHANICAL ENGINEER']\n",
    "df_emp = frame[frame['employer'].isin(emp_conditions)]\n",
    "df_city = frame[frame['city'].isin(city_conditions)]\n",
    "df_state = frame[frame['state'].isin(state_conditions)]\n",
    "df_title = frame[frame['job title'].isin(title_conditions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_averages_and_counts(df, groupby_col):\n",
    "    df_groupby = df.groupby(groupby_col)['base salary']\n",
    "    counts = df_groupby.count()\n",
    "    avgs = df_groupby.mean()\n",
    "    print('Item Counts: \\n', list(zip(counts.index, counts.values)))\n",
    "    print('Mean Salaries: \\n', list(zip(avgs.index,['${:,.0f}'.format(value) for value in avgs.values])))\n",
    "    \n",
    "    return list(zip(counts.index, counts.values)), list(zip(avgs.index, avgs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Counts: \n",
      " [('GEORGIA INSTITUTE OF TECHNOLOGY', 227), ('GOOGLE INC', 3675), ('OVE ARUP & PARTNERS PC', 9)]\n",
      "Mean Salaries: \n",
      " [('GEORGIA INSTITUTE OF TECHNOLOGY', '$74,135'), ('GOOGLE INC', '$133,491'), ('OVE ARUP & PARTNERS PC', '$106,252')]\n"
     ]
    }
   ],
   "source": [
    "employer_counts, employer_mean_sal = print_averages_and_counts(df_emp, 'employer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Counts: \n",
      " [('ATLANTA', 29855), ('NEW YORK', 73511)]\n",
      "Mean Salaries: \n",
      " [('ATLANTA', '$77,214'), ('NEW YORK', '$94,352')]\n"
     ]
    }
   ],
   "source": [
    "city_counts, city_mean_sal = print_averages_and_counts(df_city, 'city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Counts: \n",
      " [('GA', 57292), ('NY', 111185)]\n",
      "Mean Salaries: \n",
      " [('GA', '$74,776'), ('NY', '$87,626')]\n"
     ]
    }
   ],
   "source": [
    "state_counts, state_mean_sal = print_averages_and_counts(df_state, 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Counts: \n",
      " [('ASSISTANT PROFESSOR', 20118), ('DATA SCIENTIST', 4947), ('MECHANICAL ENGINEER', 7010)]\n",
      "Mean Salaries: \n",
      " [('ASSISTANT PROFESSOR', '$105,398'), ('DATA SCIENTIST', '$106,439'), ('MECHANICAL ENGINEER', '$72,699')]\n"
     ]
    }
   ],
   "source": [
    "job_counts, job_mean_sal = print_averages_and_counts(df_title, 'job title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take averages for the 3 job positions shown above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sal_dict = defaultdict(list)\n",
    "\n",
    "def grouped_averages_into_dict(sal_dict, count_list, mean_sal_list):\n",
    "    for key, val in count_list:\n",
    "        sal_dict[key].append(val)\n",
    "    \n",
    "    for key, val in mean_sal_list:\n",
    "        sal_dict[key].append(val)\n",
    "        \n",
    "    return sal_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sal_dict = (grouped_averages_into_dict(mean_sal_dict, employer_counts, employer_mean_sal))\n",
    "mean_sal_dict = (grouped_averages_into_dict(mean_sal_dict, state_counts, state_mean_sal))\n",
    "mean_sal_dict = (grouped_averages_into_dict(mean_sal_dict, city_counts, city_mean_sal))\n",
    "mean_sal_dict = (grouped_averages_into_dict(mean_sal_dict, job_counts, job_mean_sal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'GEORGIA INSTITUTE OF TECHNOLOGY': [227, 74135.26431718061],\n",
       "             'GOOGLE INC': [3675, 133491.231292517],\n",
       "             'OVE ARUP & PARTNERS PC': [9, 106252.22222222222],\n",
       "             'GA': [57292, 74776.30662221601],\n",
       "             'NY': [111185, 87626.47567567567],\n",
       "             'ATLANTA': [29855, 77213.94757996986],\n",
       "             'NEW YORK': [73511, 94351.66624042661],\n",
       "             'ASSISTANT PROFESSOR': [20118, 105398.12342181131],\n",
       "             'DATA SCIENTIST': [4947, 106439.0382049727],\n",
       "             'MECHANICAL ENGINEER': [7010, 72699.29486447932]})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sal_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, title in enumerate(predict_dict['job title']):\n",
    "    print('Your predicted salary as ' + title.title() + ' at ' + predict_dict['employer'][i] +\n",
    "          ' in ' + predict_dict['city'][i] + ' is ' + '${:,.0f}'.format(int(np.expm1(new_predictions[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEORGIA INSTITUTE OF TECHNOLOGY [227, 74135.26431718061]\n",
      "GOOGLE INC [3675, 133491.231292517]\n",
      "OVE ARUP & PARTNERS PC [9, 106252.22222222222]\n",
      "GA [57292, 74776.30662221601]\n",
      "NY [111185, 87626.47567567567]\n",
      "ATLANTA [29855, 77213.94757996986]\n",
      "NEW YORK [73511, 94351.66624042661]\n",
      "ASSISTANT PROFESSOR [20118, 105398.12342181131]\n",
      "DATA SCIENTIST [4947, 106439.0382049727]\n",
      "MECHANICAL ENGINEER [7010, 72699.29486447932]\n"
     ]
    }
   ],
   "source": [
    "for k, v in mean_sal_dict.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Predicted\" salaries using weighted means:\n",
      "Predicted salary as Data Scientist at Google Inc in New York is $91,537\n",
      "Predicted salary as Assistant Professor at Georgia Institute of Technology in Atlanta is $81,183\n",
      "Predicted salary as Mechanical Engineer at Ove Arup & Partners PC in New York is $89,660\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Predicted salaries from machine learning model:\n",
      "Your predicted salary as Data Scientist at Google Inc in New York is $150,212\n",
      "Your predicted salary as Assistant Professor at Georgia Institute of Technology in Atlanta is $107,958\n",
      "Your predicted salary as Mechanical Engineer at Ove Arup & Partners PC in New York is $81,461\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\"Predicted\" salaries using ordinary arithmetic mean:\n",
      "Predicted salary as Data Scientist at Google Inc in New York is $105,477\n",
      "Predicted salary as Assistant Professor at Georgia Institute of Technology in Atlanta is $82,880\n",
      "Predicted salary as Mechanical Engineer at Ove Arup & Partners PC in New York is $90,232\n"
     ]
    }
   ],
   "source": [
    "print('\"Predicted\" salaries using weighted means:')\n",
    "for i, title in enumerate(predict_dict['job title']):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for k in predict_dict.keys():\n",
    "        if k != 'submit year':\n",
    "            numerator += mean_sal_dict[predict_dict[k][i].upper()][0]*mean_sal_dict[predict_dict[k][i].upper()][1]\n",
    "            denominator += mean_sal_dict[predict_dict[k][i].upper()][0]\n",
    "    weighted_mean_sal = numerator/denominator\n",
    "    \n",
    "    print('Predicted salary as ' + title.title() + ' at ' + predict_dict['employer'][i] +\n",
    "          ' in ' + predict_dict['city'][i] + ' is ' + '${:,.0f}'.format(int(weighted_mean_sal)))\n",
    "\n",
    "print('-'*100)\n",
    "print('Predicted salaries from machine learning model:')\n",
    "for i, title in enumerate(predict_dict['job title']):\n",
    "    print('Your predicted salary as ' + title.title() + ' at ' + predict_dict['employer'][i] +\n",
    "          ' in ' + predict_dict['city'][i] + ' is ' + '${:,.0f}'.format(int(np.expm1(new_predictions[i]))))\n",
    "    \n",
    "print('-'*100)\n",
    "\n",
    "print('\"Predicted\" salaries using ordinary arithmetic mean:')\n",
    "for i, title in enumerate(predict_dict['job title']):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for k in predict_dict.keys():\n",
    "        if k != 'submit year':\n",
    "            numerator += mean_sal_dict[predict_dict[k][i].upper()][1]\n",
    "        \n",
    "    arithmetic_mean_sal = numerator/4\n",
    "    \n",
    "    print('Predicted salary as ' + title.title() + ' at ' + predict_dict['employer'][i] +\n",
    "          ' in ' + predict_dict['city'][i] + ' is ' + '${:,.0f}'.format(int(arithmetic_mean_sal)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDI-Capstone-WebApp",
   "language": "python",
   "name": "tdi-capstone-webapp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import gc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_file = (\"Dataset-for-ML-Model.csv\")\n",
    "frame = pd.read_csv(CSV_file, encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this function requires a cleaned up 'location' column with no NaN or empty strings\n",
    "def get_city_state(df):\n",
    "    df[\"state\"] = df[\"location\"].str.split().str[-1]\n",
    "    df[\"location\"].apply(lambda x: \"\".join(x.split()[1:]))\n",
    "    df[\"location\"] = df[\"location\"].apply(lambda x: x.split(\" \"))\n",
    "    df[\"city\"] = df[\"location\"].str[:-1].apply(lambda x: \" \".join(x))\n",
    "    \n",
    "    df = df[['employer', 'job title', 'base salary', 'submit date',\n",
    "       'start date', 'case status', 'submit year', 'submit month', 'state', 'city']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = get_city_state(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frame[['employer', 'job title', 'submit year', 'state', 'city']]\n",
    "y = np.log1p(frame[['base salary']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple label enconding per: https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn/47100771#47100771\n",
    "\n",
    "Note: investigate later how to save the default dict to a JSON file so I can 1) load it back later if loading the model (pickle) elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(LabelEncoder)\n",
    "cols_to_transf = ['employer','job title','state','city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_transform(df,cols_to_transf):\n",
    "    df_transf = df[cols_to_transf]\n",
    "    df_non_transf = df.drop(cols_to_transf, axis = 1)\n",
    "    \n",
    "    fit = df_transf.apply(lambda x: d[x.name].fit_transform(x))\n",
    "    \n",
    "    df = pd.concat([fit, df_non_transf], axis=1, join='outer')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_encoding(df,encoded_cols):\n",
    "    df_inverse = df[encoded_cols]\n",
    "    df_non_inv = df.drop(encoded_cols, axis = 1)\n",
    "    \n",
    "    df_inverse = df_inverse.apply(lambda x: d[x.name].inverse_transform(x))\n",
    "    df = pd.concat([df_inverse, df_non_inv], axis=1, join='outer')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_future_data(df,cols_to_transf):\n",
    "    df_transf = df[cols_to_transf]\n",
    "    df_non_transf = df.drop(cols_to_transf, axis = 1)\n",
    "    \n",
    "    fit = df_transf.apply(lambda x: d[x.name].transform(x))\n",
    "    \n",
    "    df = pd.concat([fit, df_non_transf], axis=1, join='outer')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fit_and_transform(X, cols_to_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving label encoder classes for re-use in app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in d.keys():\n",
    "    filename = '{}.npy'.format(key)\n",
    "    filename = filename.replace(' ','_')\n",
    "    np.save(filename, d[key].classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.25 # assign proportion of dataset to test set split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "del X, y; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data_column_order = ['employer', 'job title', 'state', 'city', 'submit year']\n",
    "# ['employer', 'job title', 'submit year', 'state', 'city']\n",
    "# ['employer', 'job title', 'state', 'city', 'submit year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['employer', 'job title', 'state', 'city', 'submit year'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train = xgb.DMatrix(X_train, label = y_train)\n",
    "d_valid = xgb.DMatrix(X_valid, label = y_valid)\n",
    "\n",
    "del X_train, X_valid; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"learning_rate\": 0.1, \n",
    "          \"max_depth\": 5, \n",
    "          \"min_child_weight\": 2,\n",
    "          \"eval_metric\": \"rmse\",\n",
    "          \"silent\": 1,\n",
    "          \"colsample_bytree\": 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:9.68021\tvalid-rmse:9.6808\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 20 rounds.\n",
      "[200]\ttrain-rmse:0.208275\tvalid-rmse:0.205763\n",
      "[400]\ttrain-rmse:0.195725\tvalid-rmse:0.193977\n",
      "[600]\ttrain-rmse:0.189816\tvalid-rmse:0.188953\n",
      "[800]\ttrain-rmse:0.185904\tvalid-rmse:0.185675\n",
      "[1000]\ttrain-rmse:0.182766\tvalid-rmse:0.183276\n",
      "[1200]\ttrain-rmse:0.18037\tvalid-rmse:0.181457\n",
      "[1400]\ttrain-rmse:0.178259\tvalid-rmse:0.17996\n",
      "[1600]\ttrain-rmse:0.176291\tvalid-rmse:0.178686\n",
      "[1800]\ttrain-rmse:0.174723\tvalid-rmse:0.177734\n",
      "[2000]\ttrain-rmse:0.172975\tvalid-rmse:0.176589\n",
      "[2200]\ttrain-rmse:0.17143\tvalid-rmse:0.17562\n",
      "[2400]\ttrain-rmse:0.16998\tvalid-rmse:0.174728\n",
      "[2600]\ttrain-rmse:0.168851\tvalid-rmse:0.173972\n",
      "[2800]\ttrain-rmse:0.167805\tvalid-rmse:0.17338\n",
      "[3000]\ttrain-rmse:0.166695\tvalid-rmse:0.172825\n",
      "[3200]\ttrain-rmse:0.165772\tvalid-rmse:0.172376\n",
      "[3400]\ttrain-rmse:0.165126\tvalid-rmse:0.17202\n",
      "[3600]\ttrain-rmse:0.164246\tvalid-rmse:0.171568\n",
      "[3800]\ttrain-rmse:0.16334\tvalid-rmse:0.171094\n",
      "[4000]\ttrain-rmse:0.162463\tvalid-rmse:0.17059\n",
      "[4200]\ttrain-rmse:0.161681\tvalid-rmse:0.170203\n",
      "[4400]\ttrain-rmse:0.160905\tvalid-rmse:0.169846\n",
      "[4600]\ttrain-rmse:0.160121\tvalid-rmse:0.169525\n",
      "[4800]\ttrain-rmse:0.159415\tvalid-rmse:0.169177\n",
      "[5000]\ttrain-rmse:0.158736\tvalid-rmse:0.168822\n",
      "[5200]\ttrain-rmse:0.158022\tvalid-rmse:0.168413\n",
      "[5400]\ttrain-rmse:0.157433\tvalid-rmse:0.16812\n",
      "[5600]\ttrain-rmse:0.156723\tvalid-rmse:0.167785\n",
      "[5800]\ttrain-rmse:0.156174\tvalid-rmse:0.167555\n",
      "[6000]\ttrain-rmse:0.155475\tvalid-rmse:0.167202\n",
      "[6200]\ttrain-rmse:0.154849\tvalid-rmse:0.166904\n",
      "[6400]\ttrain-rmse:0.154354\tvalid-rmse:0.166599\n",
      "[6600]\ttrain-rmse:0.153801\tvalid-rmse:0.166329\n",
      "[6800]\ttrain-rmse:0.153207\tvalid-rmse:0.166069\n",
      "[7000]\ttrain-rmse:0.152664\tvalid-rmse:0.165872\n",
      "Stopping. Best iteration:\n",
      "[7161]\ttrain-rmse:0.152289\tvalid-rmse:0.165738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "clf = xgb.train(params, d_train, num_boost_round=10000, evals=watchlist,early_stopping_rounds=20,verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TDI-XGB_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction RMSE = 0.1674\n",
      "R2 = 0.720\n"
     ]
    }
   ],
   "source": [
    "print('Prediction RMSE = {:.4f}'.format(np.sqrt(mean_squared_error(y_test, predict))))\n",
    "print('R2 = {:.3f}'.format(r2_score(y_test, predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employer</th>\n",
       "      <th>job title</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>submit year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460019</th>\n",
       "      <td>40289</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>6798</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924125</th>\n",
       "      <td>15309</td>\n",
       "      <td>210</td>\n",
       "      <td>47</td>\n",
       "      <td>5312</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        employer  job title  state  city  submit year\n",
       "460019     40289         86      5  6798         2015\n",
       "924125     15309        210     47  5312         2018"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dict = {\n",
    "    'employer':     ['Google Inc', 'Georgia Institute of Technology','Ove Arup & Partners PC'],\n",
    "    'job title':    ['Data Scientist', 'Assistant Professor', 'Mechanical Engineer'],\n",
    "    'state':        ['NY', 'GA', 'NY'],\n",
    "    'city':         ['New York', 'Atlanta', 'New York'],\n",
    "    'submit year':  [2018, 2018, 2018]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_new_data(dict,cols_to_transf,future_data_column_order):\n",
    "    predict_df = pd.DataFrame.from_dict(predict_dict)\n",
    "    predict_df_transf = predict_df[cols_to_transf]\n",
    "    predict_df_non_transf = predict_df.drop(cols_to_transf, axis=1)\n",
    "    \n",
    "    for col in predict_df_transf.columns:\n",
    "        predict_df_transf[col] = predict_df_transf[col].str.upper()\n",
    "    \n",
    "    predict_df = pd.concat([predict_df_transf, predict_df_non_transf], axis=1, join='outer')\n",
    "    \n",
    "    predict_df = encode_future_data(predict_df,cols_to_transf)\n",
    "    \n",
    "    predict_df = predict_df[future_data_column_order]\n",
    "    \n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/PycharmProjects/Capstone-WebApp/venv/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "predict_df = preprocess_new_data(predict_dict, cols_to_transf,future_data_column_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_new_data = xgb.DMatrix(predict_df)\n",
    "new_predictions = clf.predict(d_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your predicted salary as Data Scientist at Google Inc in New York is $150,212\n",
      "Your predicted salary as Assistant Professor at Georgia Institute of Technology in Atlanta is $107,958\n",
      "Your predicted salary as Mechanical Engineer at Ove Arup & Partners PC in New York is $81,461\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(predict_dict['job title']):\n",
    "    print('Your predicted salary as ' + title.title() + ' at ' + predict_dict['employer'][i] +\n",
    "          ' in ' + predict_dict['city'][i] + ' is ' + '${:,.0f}'.format(int(np.expm1(new_predictions[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export location, employer, job title lists for use in app\n",
    "Only entries with counts > 10 will be exported to avoid too many items in the app dropdown menu, which slows down the app significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Locations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['location'] = frame['city']+ ', '  + frame['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = frame[['location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_counts = frame['location'].value_counts().reset_index().rename(columns={'location': 'counts', 'index': 'location'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations.merge(location_counts, on='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations[locations['counts'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_locations = sorted(set(locations['location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13994\n",
      "3262\n"
     ]
    }
   ],
   "source": [
    "print(len(set(frame['location'])))\n",
    "print(len(unique_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Job Titles***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = frame[['job title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_counts = frame['job title'].value_counts().reset_index().rename(columns={'job title': 'counts', 'index': 'job title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = job_titles.merge(job_title_counts, on='job title')\n",
    "job_titles = job_titles[job_titles['counts'] > 10]\n",
    "unique_job_titles = sorted(set(job_titles['job title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7722\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(set(frame['job title'])))\n",
    "print(len(unique_job_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Companies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = frame[['employer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_counts = frame['employer'].value_counts().reset_index().rename(columns={'employer': 'counts', 'index': 'employer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = companies.merge(companies_counts, on='employer')\n",
    "companies = companies[companies['counts'] > 10]\n",
    "unique_companies = sorted(set(companies['employer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78673\n",
      "9421\n"
     ]
    }
   ],
   "source": [
    "print(len(set(frame['employer'])))\n",
    "print(len(unique_companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_state_abbr(location_list):\n",
    "    for location in location_list:\n",
    "        if re.match('[\\w]+',location[0]):\n",
    "            duplicate_chk = re.findall('[\\w]+',location[0])\n",
    "            for item in duplicate_chk:\n",
    "                if item == location[1].strip():\n",
    "                    try:\n",
    "                        location[0] = location[0].replace(item,'')\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "    return location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_locations(location_list):\n",
    "    location_list = [''.join(c for c in string if not c.isdigit()) for string in location_list]\n",
    "    location_list = [location.replace('#','') for location in location_list]\n",
    "    location_list = [location.replace('MSA','') for location in location_list]\n",
    "    location_list = [location.replace('DIV','') for location in location_list]\n",
    "    location_list = [location.replace('&NBSP','') for location in location_list]\n",
    "    location_list = [location.replace(';','') for location in location_list]\n",
    "    location_list = [location.replace(':','') for location in location_list]\n",
    "    location_list = [location.strip() for location in location_list]\n",
    "    location_list = [location.split(',') for location in location_list]\n",
    "    #location_list = [location for location in location_list if location not in wrongly_mispelled_locations]\n",
    "    location_list = remove_duplicate_state_abbr(location_list)\n",
    "    location_list = [location for location in location_list if len(location[0]) > 0]\n",
    "    location_list = [[re.sub(' +', ' ', location[0]), location[1]] for location in location_list]\n",
    "    location_list = sorted(location_list, key=lambda x: x[1])\n",
    "    location_list = [','.join(item) for item in location_list]\n",
    "    location_list = sorted(set(location_list), key=location_list.index)\n",
    "    return location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3254\n",
      "3254\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_locations))\n",
    "unique_locations = cleanup_locations(unique_locations)\n",
    "print(len(unique_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_locations2[:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('locations-list.txt', 'w') as f:\n",
    "    for item in unique_locations:\n",
    "        f.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('employers-list.txt', 'w') as f:\n",
    "    for item in unique_companies:\n",
    "        f.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('job-titles-list.txt', 'w') as f:\n",
    "    for item in unique_job_titles:\n",
    "        f.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDI-Capstone-WebApp",
   "language": "python",
   "name": "tdi-capstone-webapp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
